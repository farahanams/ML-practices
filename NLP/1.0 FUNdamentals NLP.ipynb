{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of NLP\n",
    "#### By: Farahana, Date: 13/8/2020\n",
    "\n",
    "I've never tried NLP in my life. This is my first time trying to get into this. We will try to go together from here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model: Bag of Words\n",
    "\n",
    "In data science, it is easy to work with numerical values rather than a non-numerical values such as words. This model is the easiest model to convert sentences into numerical values/vectors. For instance;\n",
    "\n",
    "* \"I love the book\"\n",
    "* \"This is a great book\"\n",
    "* \"The fit is great\"\n",
    "* \"I love the shoes\"\n",
    "\n",
    "we can extract <1> _unique_ words from the sentences above and turn into:\n",
    "\n",
    "* \"I love the book this is a great fit shoes\"\n",
    "\n",
    "Then <2> we will create a vector for each and every sentence that has that unique word. We will implement scikit-learn [CountVectorizer](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) from here on: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessities\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us try with the example as training set\n",
    "x_train = [\"I love the book\", \"This is a great book\", \"The fit is great\", \"I love the shoes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then let us fit it into CountVectorizer (as a dictionary) into our training set\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us check our vectors and test something with it.\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
      "[[1 0 0 0 1 0 1 0]\n",
      " [1 0 1 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 1 0]\n",
      " [0 0 0 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()) # get the unique words as features for the training set\n",
    "print(vectors.toarray()) # convert the training set into binary array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phrase return `book`,`1`; `fit`,`0`; `great`,`0`; `is`,`0`; `love`,`1`; `shoes`,`0`; and so on as in \"I love the book\" for the first row of `vector`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try to make a proper dataset similar to the above training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    BOOKS = \"BOOKS\"\n",
    "    CLOTHING = \"CLOTHING\"\n",
    "    \n",
    "X_train = [\"I love the book\", \"This is a great book\", \"The fit is great\", \"I love the shoes\"]\n",
    "y_train = [Category.BOOKS, Category.BOOKS, Category.CLOTHING, Category.CLOTHING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vector_train = vectorizer.fit_transform(X_train) # define the x_train as vector for the classification purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will try to use simple machine learning technique for the above dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_vector_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try to predict simple sentence to have the SVM classifier classes it according to its `Category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ['I like the book']\n",
    "X_vector_test = vectorizer.transform(X_test) # as usual, sentence is supposed to be in vector (0,1) for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOOKS'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_vector_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above example is a unigram approach where each word is taken as feature. However, when we have tenses such as _\"was doing\"_ and _\"is doing\"_, and sentiment such _\"very good\"_ and _\"very bad\"_, we have to consider pairing the words to be more than one. Let us check a vectorizer in effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'fit', 'fit is', 'great', 'great book', 'is', 'is great', 'love', 'love the', 'shoes', 'the', 'the book', 'the fit', 'the shoes', 'this', 'this is']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2)) # With 1 and 2 words.\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "print (vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have 16 features in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
